{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a Text File to Find Wikipedia Links\n",
    "\n",
    "The case when we have also Birth and Death dates to help improve disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def pre_process_list(filepath: str):\n",
    "    with open(filepath) as f:\n",
    "        rows = f.readlines()\n",
    "\n",
    "    life_pattern = r\"(\\d+)\\s+(â€“|-)\\s+(\\d+)\"\n",
    "    people = []\n",
    "    for row in rows:\n",
    "        if '(' in row and ')' in row:\n",
    "            bracket_open_index = row.index('(')\n",
    "            bracket_closed_index = row.index(')')\n",
    "            name = row[:bracket_open_index].strip()\n",
    "            lifespan = row[bracket_open_index:bracket_closed_index+1].strip()\n",
    "            if len(row) > bracket_closed_index+1:\n",
    "                description = row[bracket_closed_index+1:].strip()\n",
    "            else:\n",
    "                description = \"\"\n",
    "            m = re.search(life_pattern, lifespan)\n",
    "            if m:\n",
    "                birth = m.group(1).strip()\n",
    "                death = m.group(3).strip()\n",
    "            else:\n",
    "                birth = -1\n",
    "                death = -1\n",
    "            people.append((name, int(birth), int(death)))\n",
    "            # print(\"Name:\", name)\n",
    "            # print(\"Lifespan:\", lifespan, birth, death)\n",
    "            # print(\"Description:\", description)\n",
    "            # print(\"---\")\n",
    "        else:\n",
    "            print(\"MISSED\", row)\n",
    "    \n",
    "    return people\n",
    "\n",
    "def pre_process_latinamerica_list(filepath: str):\n",
    "    with open(filepath) as f:\n",
    "        rows = f.readlines()\n",
    "    people = []\n",
    "    countries = []\n",
    "    for row in rows:\n",
    "        columns = row.split('|')\n",
    "        name = columns[0].strip()\n",
    "        country = columns[1].strip()\n",
    "        countries.append(country)\n",
    "        birth = -1\n",
    "        death = -1\n",
    "        people.append((name, int(birth), int(death)))\n",
    "    \n",
    "    [print(x) for x in Counter(countries).most_common()]\n",
    "    return people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_wiki import get_wikipedia_article, save_wikipedia_page\n",
    "import time, os\n",
    "from typing import List, Tuple\n",
    "from urllib.parse import unquote\n",
    "\n",
    "def create_ready_filelist(people: List[Tuple], output_list: str, output_dir: str):\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    with open(output_list, \"w\") as f:\n",
    "        for name, birth, death in people:\n",
    "            page = get_wikipedia_article(name, query_restrictions={'birth_year': birth, 'death_year': death})\n",
    "            if page:\n",
    "                save_wikipedia_page(page, output_path=f\"{output_dir}/{page.title.replace(' ', '_').lower()}.txt\", include_metadata=True, include_sections=True, include_infobox=True)\n",
    "                f.write(f\"{page.title} | {page.url}\\n\")\n",
    "            time.sleep(5)\n",
    "\n",
    "def get_person_name(wiki_link: str):\n",
    "    if \"/\" not in wiki_link: return None\n",
    "    name_url = wiki_link.split(\"/\")[-1]\n",
    "    person_name = unquote(name_url)\n",
    "    return person_name.replace(\"_\", \" \")\n",
    "\n",
    "def get_pages_from_ready(filepath: str, output_dir: str):\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    wiki_titles = []\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            elems = line.split(\"|\")\n",
    "            person_wiki_name = get_person_name(elems[1].strip())\n",
    "            wiki_titles.append(person_wiki_name)\n",
    "    for title in wiki_titles:\n",
    "        page = get_wikipedia_article(title)\n",
    "        if page:\n",
    "            save_wikipedia_page(page, output_path=f\"{output_dir}/{page.title.replace(' ', '_').lower()}.txt\", include_metadata=True, include_sections=True, include_infobox=True)\n",
    "        time.sleep(5)\n",
    "\n",
    "# women_famous = pre_process_list(\"resources/15_famous_women.txt\")\n",
    "# create_ready_filelist(women_famous, \"resources/15_famous_women.ready.txt\", \"data/wikipedia/top_women\")\n",
    "\n",
    "# get_pages_from_ready(\"resources/12_activists_lgbtq.ready.txt\", \"data/wikipedia/top_lgbtq\")\n",
    "\n",
    "# get_pages_from_ready(\"resources/50_famous_mexico.ready.txt\", \"data/wikipedia/top_mexico\")\n",
    "\n",
    "# top_100_people = pre_process_list(\"resources/top_100_world_most_influential.txt\")\n",
    "# create_ready_filelist(top_100_people, \"resources/top_100_world_most_influential.ready.txt\", \"data/wikipedia/top100\")\n",
    "\n",
    "# get_pages_from_ready(\"resources/100_famous_latinamerica.ready.txt\", \"data/wikipedia/top_latinamerica\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a Wikipedia Page with a Table\n",
    "\n",
    "The case of the \"List of women explorers and travelers\" [Link](https://en.wikipedia.org/wiki/List_of_women_explorers_and_travelers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
